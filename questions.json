[
  {
    "question": "What is a characteristic of a good algorithm?",
    "options": ["Complexity", "Slowness", "Correctness", "High memory usage"],
    "correct": 2,
    "explanation": "A good algorithm must be correct, meaning it produces the right output for all valid inputs."
  },
  {
    "question": "Which of the following is an example of algorithm application?",
    "options": [
      "Sleeping",
      "Cooking a dish",
      "Driving randomly",
      "Watching TV"
    ],
    "correct": 1,
    "explanation": "Cooking a dish follows a step-by-step procedure, which is essentially an algorithm."
  },
  {
    "question": "What is the time complexity of the linear search algorithm?",
    "options": ["O(1)", "O(n)", "O(n²)", "O(log n)"],
    "correct": 1,
    "explanation": "Linear search checks each element in sequence, so its time complexity is O(n)."
  },
  {
    "question": "Which method helps overcome the limitations of practical testing?",
    "options": [
      "Trial and error",
      "Manual comparison",
      "Theoretical analysis",
      "Visualization"
    ],
    "correct": 2,
    "explanation": "Theoretical analysis provides general performance insights without relying on specific hardware or input."
  },
  {
    "question": "Which Big-O notation represents quadratic time complexity?",
    "options": ["O(1)", "O(n)", "O(n²)", "O(log n)"],
    "correct": 2,
    "explanation": "O(n²) represents algorithms where runtime increases quadratically with input size."
  },
  {
    "question": "Which of the following is NOT a step in algorithmic problem-solving?",
    "options": [
      "Problem Definition",
      "Algorithm Design",
      "Guessing the Output",
      "Testing"
    ],
    "correct": 2,
    "explanation": "Guessing the output is not a systematic approach in algorithm design."
  },
  {
    "question": "What is the main focus of asymptotic analysis?",
    "options": [
      "Exact execution time",
      "Worst-case machine behavior",
      "Behavior as input size grows",
      "Input data types"
    ],
    "correct": 2,
    "explanation": "Asymptotic analysis studies how an algorithm behaves as the input size approaches infinity."
  },
  {
    "question": "Which of the following best describes O(1) time complexity?",
    "options": [
      "Time grows with input",
      "Constant time regardless of input size",
      "Exponential growth",
      "Depends on loop depth"
    ],
    "correct": 1,
    "explanation": "O(1) means that the operation takes constant time, no matter how large the input is."
  },
  {
    "question": "What is an advantage of theoretical analysis over practical testing?",
    "options": [
      "Depends on specific hardware",
      "Covers only one input",
      "Predicts performance in general",
      "Requires more memory"
    ],
    "correct": 2,
    "explanation": "Theoretical analysis allows us to predict how an algorithm will perform across different inputs and machines."
  },
  {
    "question": "Which algorithm is more efficient for large input sizes in finding the largest number?",
    "options": [
      "Compare All Pairs",
      "Linear Search",
      "Guess and Check",
      "Recursive Tree"
    ],
    "correct": 1,
    "explanation": "Linear search efficiently finds the largest number in O(n) time, better than O(n²) alternatives."
  },
  {
    "question": "What is the primary reason for analyzing an algorithm?",
    "options": [
      "To write more code",
      "To make the program longer",
      "To choose the best and most efficient solution",
      "To confuse the programmer"
    ],
    "correct": 2,
    "explanation": "We analyze algorithms to compare their efficiency and choose the best option for solving a problem."
  },
  {
    "question": "Which of the following defines how an algorithm’s performance grows with input size?",
    "options": ["Pseudo-code", "Flowchart", "Big-O Notation", "Source Code"],
    "correct": 2,
    "explanation": "Big-O notation measures how an algorithm's runtime or space requirements grow as input size increases."
  },
  {
    "question": "What is the time complexity of comparing all pairs in a list of n numbers?",
    "options": ["O(n)", "O(log n)", "O(n²)", "O(1)"],
    "correct": 2,
    "explanation": "Comparing all pairs involves nested loops, resulting in O(n²) time complexity."
  },
  {
    "question": "What does robustness in an algorithm mean?",
    "options": [
      "It always gives a wrong output",
      "It only works for specific input",
      "It fails under edge cases",
      "It handles unexpected inputs gracefully"
    ],
    "correct": 3,
    "explanation": "Robustness refers to an algorithm's ability to handle invalid or unexpected inputs without crashing."
  },
  {
    "question": "What does 'space complexity' refer to?",
    "options": [
      "Disk size",
      "Screen resolution",
      "Amount of memory used by the algorithm",
      "The number of files"
    ],
    "correct": 2,
    "explanation": "Space complexity measures the amount of memory an algorithm uses during execution."
  },
  {
    "question": "Algorithms are only useful for computer programming tasks.",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "Algorithms are used in many areas beyond programming, such as cooking, navigation, and decision-making."
  },
  {
    "question": "Big-O notation describes the exact execution time of an algorithm.",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "Big-O notation focuses on growth rate, not exact time."
  },
  {
    "question": "Scalability is a key criterion in algorithm evaluation.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "An algorithm should scale well with increasing input size."
  },
  {
    "question": "Time complexity measures how memory usage grows with input size.",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "Time complexity measures runtime, while space complexity measures memory usage."
  },
  {
    "question": "The worst-case analysis considers the maximum time an algorithm will take.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Worst-case analysis gives an upper bound on the runtime."
  },
  {
    "question": "Big-O notation focuses on the best-case scenario of an algorithm.",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "Big-O is used to describe the upper bound (worst-case), not the best-case."
  },
  {
    "question": "Space complexity includes both fixed and variable parts.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Space complexity accounts for both static and dynamic memory usage."
  },
  {
    "question": "All efficient algorithms are always accurate.",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "An algorithm can be fast but incorrect if it doesn’t produce the right output."
  },
  {
    "question": "Theoretical analysis helps avoid unnecessary coding.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "By analyzing algorithms beforehand, we can eliminate inefficient options early."
  },
  {
    "question": "Time vs. Space is a common trade-off in algorithm design.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Improving speed may require more memory, and vice versa."
  },
  {
    "question": "Practical testing of algorithms depends on the hardware used.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Performance in practice can vary based on system specs."
  },
  {
    "question": "Big-O notation considers minor constants and hardware speed.",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "Big-O ignores constants and hardware-specific details, focusing on growth rates."
  },
  {
    "question": "The main goal of algorithm design is to use as many resources as possible.",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "Efficiency aims to minimize resource usage, not maximize it."
  },
  {
    "question": "The 'Compare All Pairs' algorithm is more efficient than linear search.",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "Compare All Pairs has O(n²) time complexity, which is slower than linear search's O(n)."
  },
  {
    "question": "Big-O notation helps compare two algorithms even before coding them.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, this is one of the main purposes of Big-O notation."
  },

  {
    "question": "What is the best-case time complexity of Bubble Sort?",
    "options": ["O(N²)", "O(N)", "O(log N)", "O(N log N)"],
    "correct": 1,
    "explanation": "In the best case, where the array is already sorted, Bubble Sort performs only one pass with no swaps."
  },
  {
    "question": "Which sorting algorithm divides the array into a sorted and unsorted subarray and selects the smallest element from the unsorted subarray?",
    "options": [
      "Bubble Sort",
      "Selection Sort",
      "Insertion Sort",
      "Quick Sort"
    ],
    "correct": 1,
    "explanation": "Selection Sort repeatedly finds the minimum element from the unsorted part and places it at the beginning."
  },
  {
    "question": "What is the space complexity of Insertion Sort?",
    "options": ["O(N)", "O(N²)", "O(1)", "O(log N)"],
    "correct": 2,
    "explanation": "Insertion Sort sorts in-place and requires only a few temporary variables."
  },
  {
    "question": "Which sorting algorithm has the worst-case time complexity of O(N²)?",
    "options": ["Merge Sort", "Quick Sort", "Bubble Sort", "Heap Sort"],
    "correct": 2,
    "explanation": "Bubble Sort can have a worst-case time complexity of O(N²), especially when the list is in reverse order."
  },
  {
    "question": "What is the average-case time complexity of Quick Sort?",
    "options": ["O(N²)", "O(N log N)", "O(N)", "O(log N)"],
    "correct": 1,
    "explanation": "Quick Sort uses divide-and-conquer and on average splits the data efficiently."
  },
  {
    "question": "Which sorting algorithm is most efficient for nearly sorted arrays?",
    "options": [
      "Bubble Sort",
      "Selection Sort",
      "Insertion Sort",
      "Radix Sort"
    ],
    "correct": 2,
    "explanation": "Insertion Sort is fast for nearly sorted arrays because it shifts elements rather than swapping them all."
  },
  {
    "question": "What is the space complexity of Merge Sort?",
    "options": ["O(1)", "O(N)", "O(N log N)", "O(N²)"],
    "correct": 1,
    "explanation": "Merge Sort requires additional memory to merge the subarrays."
  },
  {
    "question": "Which sorting algorithm uses buckets to sort elements?",
    "options": ["Counting Sort", "Bucket Sort", "Radix Sort", "Heap Sort"],
    "correct": 1,
    "explanation": "Bucket Sort distributes elements into buckets and then sorts each bucket individually."
  },
  {
    "question": "What is the best-case time complexity of Selection Sort?",
    "options": ["O(N²)", "O(N)", "O(log N)", "O(N log N)"],
    "correct": 0,
    "explanation": "Selection Sort always runs in O(N²) even if the array is already sorted."
  },
  {
    "question": "Which sorting algorithm is based on the divide-and-conquer approach?",
    "options": [
      "Bubble Sort",
      "Merge Sort",
      "Selection Sort",
      "Insertion Sort"
    ],
    "correct": 1,
    "explanation": "Merge Sort recursively divides the array into halves, sorts them, and merges them back together."
  },
  {
    "question": "What is the worst-case time complexity of Heap Sort?",
    "options": ["O(N²)", "O(N log N)", "O(N)", "O(log N)"],
    "correct": 1,
    "explanation": "Heap Sort maintains a heap structure and extracts elements in order, resulting in O(N log N) performance."
  },
  {
    "question": "Which sorting algorithm is non-comparison-based?",
    "options": ["Quick Sort", "Counting Sort", "Bubble Sort", "Selection Sort"],
    "correct": 1,
    "explanation": "Counting Sort uses counting instead of comparisons between elements."
  },
  {
    "question": "What is the space complexity of Radix Sort?",
    "options": ["O(N)", "O(N + k)", "O(N²)", "O(log N)"],
    "correct": 1,
    "explanation": "Radix Sort uses extra space proportional to the number of elements and possible values (k)."
  },
  {
    "question": "Which sorting algorithm is most suitable for sorting large datasets with a small range of values?",
    "options": ["Bubble Sort", "Counting Sort", "Quick Sort", "Merge Sort"],
    "correct": 1,
    "explanation": "Counting Sort is efficient when the range of input values is not significantly greater than the number of elements."
  },
  {
    "question": "What is the worst-case time complexity of Quick Sort?",
    "options": ["O(N²)", "O(N log N)", "O(N)", "O(log N)"],
    "correct": 0,
    "explanation": "In the worst case (e.g., already sorted), Quick Sort degrades to O(N²) due to poor pivot selection."
  },
  {
    "question": "Which sorting algorithm repeatedly swaps adjacent elements if they are in the wrong order?",
    "options": [
      "Bubble Sort",
      "Selection Sort",
      "Insertion Sort",
      "Merge Sort"
    ],
    "correct": 0,
    "explanation": "This describes the core mechanism of Bubble Sort."
  },
  {
    "question": "What is the average-case time complexity of Bubble Sort?",
    "options": ["O(N²)", "O(N)", "O(log N)", "O(N log N)"],
    "correct": 0,
    "explanation": "Bubble Sort typically makes multiple passes over the array, leading to quadratic time complexity."
  },
  {
    "question": "Which sorting algorithm builds a sorted array one element at a time?",
    "options": [
      "Bubble Sort",
      "Selection Sort",
      "Insertion Sort",
      "Quick Sort"
    ],
    "correct": 2,
    "explanation": "Insertion Sort inserts each new element into its correct position within the sorted portion."
  },
  {
    "question": "What is the best-case time complexity of Merge Sort?",
    "options": ["O(N²)", "O(N log N)", "O(N)", "O(log N)"],
    "correct": 1,
    "explanation": "Merge Sort always divides and merges the array, so its best-case is still O(N log N)."
  },
  {
    "question": "Which sorting algorithm is most efficient for sorting integers with a fixed range?",
    "options": ["Radix Sort", "Quick Sort", "Bubble Sort", "Selection Sort"],
    "correct": 0,
    "explanation": "Radix Sort is efficient for fixed-range integers by sorting digit-by-digit."
  },
  {
    "question": "Bubble Sort has a space complexity of O(N).",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "Bubble Sort is an in-place algorithm with a space complexity of O(1)."
  },
  {
    "question": "Selection Sort performs fewer swaps than Bubble Sort.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Selection Sort only swaps once per iteration, while Bubble Sort may swap many times."
  },
  {
    "question": "Insertion Sort is more efficient for nearly sorted arrays.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, because it minimizes the number of comparisons and shifts needed."
  },
  {
    "question": "Quick Sort has a worst-case time complexity of O(N log N).",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "No, Quick Sort's worst-case is O(N²) when the pivot selection is poor."
  },
  {
    "question": "Merge Sort is based on the divide-and-conquer approach.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, Merge Sort divides the array into halves, sorts them recursively, and merges them."
  },
  {
    "question": "Counting Sort is a comparison-based sorting algorithm.",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "No, Counting Sort uses counting and indexing instead of comparing elements."
  },
  {
    "question": "Radix Sort is suitable for sorting floating-point numbers.",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "No, Radix Sort is typically used for integers or strings with fixed digits."
  },
  {
    "question": "Heap Sort has a space complexity of O(N).",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "No, Heap Sort works in-place and has a space complexity of O(1)."
  },
  {
    "question": "Bucket Sort is efficient for sorting elements with a uniform distribution.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, Bucket Sort performs well when data is uniformly distributed across the range."
  },
  {
    "question": "The best-case time complexity of Selection Sort is O(N).",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "No, Selection Sort always takes O(N²) regardless of the initial arrangement."
  },

  {
    "question": "What does Big O notation measure?",
    "options": [
      "Best-case scenario",
      "Average-case scenario",
      "Worst-case scenario",
      "None of the above"
    ],
    "correct": 2,
    "explanation": "Big O notation focuses on the worst-case scenario to describe the upper bound of an algorithm's runtime."
  },
  {
    "question": "Which of the following is ignored in Big O notation?",
    "options": ["Dominant term", "Constants", "Input size", "Recursive calls"],
    "correct": 1,
    "explanation": "In Big O analysis, constants are dropped because they become insignificant for large input sizes."
  },
  {
    "question": "What is the time complexity of accessing an array element?",
    "options": ["O(n)", "O(log n)", "O(1)", "O(n²)"],
    "correct": 2,
    "explanation": "Arrays allow direct access to elements using their index, which takes constant time."
  },
  {
    "question": "What is the time complexity of a nested loop where both loops run n times?",
    "options": ["O(n)", "O(n²)", "O(log n)", "O(n log n)"],
    "correct": 1,
    "explanation": "Each iteration of the outer loop causes n iterations of the inner loop, resulting in n * n = O(n²)."
  },
  {
    "question": "What is the dominant term in O(n² + n)?",
    "options": ["O(n)", "O(n²)", "O(1)", "O(log n)"],
    "correct": 1,
    "explanation": "As input size grows, the quadratic term dominates and other terms become negligible."
  },
  {
    "question": "What is the time complexity of binary search?",
    "options": ["O(n)", "O(log n)", "O(n²)", "O(1)"],
    "correct": 1,
    "explanation": "Binary search reduces the search space by half at each step, leading to logarithmic time."
  },
  {
    "question": "Which rule is used to combine complexities of sequential steps in an algorithm?",
    "options": [
      "Product Rule",
      "Sum Rule",
      "Dominant Term Rule",
      "Constant Rule"
    ],
    "correct": 1,
    "explanation": "The Sum Rule applies when steps are executed one after another."
  },
  {
    "question": "What is the time complexity of a recursive algorithm with n recursive calls and O(1) work per call?",
    "options": ["O(n)", "O(n²)", "O(log n)", "O(1)"],
    "correct": 0,
    "explanation": "Each recursive call performs constant-time work, so total work is proportional to the number of calls."
  },
  {
    "question": "What is the input size (n) in a sorting algorithm?",
    "options": [
      "Number of comparisons",
      "Number of elements in the array",
      "Number of recursive calls",
      "Number of loops"
    ],
    "correct": 1,
    "explanation": "Input size typically refers to the number of elements being processed."
  },
  {
    "question": "Which of the following complexities is considered the most efficient?",
    "options": ["O(n²)", "O(n log n)", "O(log n)", "O(n)"],
    "correct": 2,
    "explanation": "Logarithmic time is more efficient than linear or higher-order complexities."
  },
  {
    "question": "What happens to the search space in binary search during each iteration?",
    "options": ["Doubles", "Halves", "Remains constant", "Triples"],
    "correct": 1,
    "explanation": "Binary search divides the search space in half each time, reducing it exponentially fast."
  },
  {
    "question": "What is the time complexity of Merge Sort?",
    "options": ["O(n)", "O(n²)", "O(n log n)", "O(log n)"],
    "correct": 2,
    "explanation": "Merge Sort splits the array and merges sorted halves, leading to O(n log n) performance."
  },
  {
    "question": "Which property of Big O states that constants are ignored?",
    "options": [
      "Transitivity",
      "Additivity",
      "Constants are Ignored",
      "Dominant Term"
    ],
    "correct": 2,
    "explanation": "Big O notation abstracts away constants since they don't significantly affect performance for large inputs."
  },
  {
    "question": "What is the time complexity of a simple loop that runs n times?",
    "options": ["O(n²)", "O(n)", "O(log n)", "O(1)"],
    "correct": 1,
    "explanation": "A single loop that iterates n times has linear time complexity."
  },
  {
    "question": "What is the time complexity of nested loops where the outer loop runs n times and the inner loop runs n times?",
    "options": ["O(n)", "O(n²)", "O(log n)", "O(1)"],
    "correct": 1,
    "explanation": "This results in n * n = O(n²) operations."
  },
  {
    "question": "Which rule is used to simplify O(5n) to O(n)?",
    "options": [
      "Drop Constants",
      "Drop Lower-Order Terms",
      "Sum Rule",
      "Product Rule"
    ],
    "correct": 0,
    "explanation": "Big O notation ignores constants, so O(5n) simplifies to O(n)."
  },
  {
    "question": "What is the time complexity of the factorial function?",
    "options": ["O(n²)", "O(n)", "O(log n)", "O(1)"],
    "correct": 1,
    "explanation": "Factorial recursion makes n calls, each doing constant work, leading to O(n) complexity."
  },
  {
    "question": "What is the time complexity of accessing an element in a linked list?",
    "options": ["O(n)", "O(log n)", "O(1)", "O(n²)"],
    "correct": 0,
    "explanation": "Unlike arrays, linked lists require traversal from the head to reach a specific element."
  },
  {
    "question": "Which of the following is an example of quadratic time complexity?",
    "options": ["Binary search", "Nested loops", "Merge Sort", "Simple loop"],
    "correct": 1,
    "explanation": "Nested loops with both running n times result in O(n²) time complexity."
  },
  {
    "question": "What is the time complexity of a loop that runs log n times?",
    "options": ["O(n)", "O(log n)", "O(n²)", "O(1)"],
    "correct": 1,
    "explanation": "If the loop counter increases or decreases exponentially, the time complexity is logarithmic."
  },
  {
    "question": "Big O notation focuses on the best-case scenario.",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "Big O describes the worst-case growth rate of an algorithm."
  },
  {
    "question": "Constants are ignored in Big O notation.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, because they do not significantly impact performance for large input sizes."
  },
  {
    "question": "The dominant term in O(n² + n) is O(n).",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "No, O(n²) is the dominant term as it grows faster than O(n)."
  },
  {
    "question": "Binary search has a time complexity of O(log n).",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, binary search repeatedly halves the search space."
  },
  {
    "question": "Nested loops with n iterations each have a time complexity of O(n²).",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, because the total number of operations is n × n."
  },
  {
    "question": "The sum rule is used for nested steps in an algorithm.",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "No, the product rule is used for nested steps; the sum rule is for sequential steps."
  },
  {
    "question": "The product rule is used for sequential steps in an algorithm.",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "No, the product rule is used for nested loops or recursive steps."
  },
  {
    "question": "The time complexity of a simple loop is O(n).",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, if the loop runs n times without nested logic."
  },
  {
    "question": "Merge Sort has a time complexity of O(n log n).",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, due to its divide-and-conquer approach."
  },
  {
    "question": "Recursive algorithms can be analyzed using the Master Theorem.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, the Master Theorem helps analyze recurrence relations common in recursive algorithms."
  },

  {
    "question": "What is a characteristic of linear search?",
    "options": [
      "Requires sorted data",
      "Iterates through each element one by one",
      "Significantly faster for large datasets",
      "Uses a divide-and-conquer approach"
    ],
    "correct": 1,
    "explanation": "Linear search checks each element sequentially until the target is found or the end of the list is reached."
  },
  {
    "question": "Which algorithm is more efficient for searching in sorted collections?",
    "options": [
      "Linear Search",
      "Binary Search",
      "Bubble Sort",
      "Selection Sort"
    ],
    "correct": 1,
    "explanation": "Binary search takes advantage of sorted data and reduces the search space by half at each step."
  },
  {
    "question": "What is the time complexity of linear search in the worst case?",
    "options": ["O(log n)", "O(n)", "O(n log n)", "O(1)"],
    "correct": 1,
    "explanation": "In the worst case, linear search may need to check all elements."
  },
  {
    "question": "What is the primary advantage of binary search over linear search?",
    "options": [
      "Simplicity",
      "Works with unsorted data",
      "Faster for large datasets",
      "Can be implemented recursively"
    ],
    "correct": 2,
    "explanation": "Binary search has a logarithmic time complexity O(log n), making it much faster than linear search for large arrays."
  },
  {
    "question": "What type of dataset can linear search work with?",
    "options": [
      "Only sorted",
      "Only unsorted",
      "Both sorted and unsorted",
      "None of the above"
    ],
    "correct": 2,
    "explanation": "Unlike binary search, linear search does not require the array to be sorted."
  },
  {
    "question": "In binary search, when is the search interval halved?",
    "options": [
      "Each time the target is less than the middle element",
      "Each time the target is greater than the middle element",
      "Both A and B",
      "Never"
    ],
    "correct": 2,
    "explanation": "The search interval is halved whether the target is smaller or larger than the current midpoint."
  },
  {
    "question": "In the binary search algorithm, what happens when the target is found?",
    "options": [
      "The algorithm stops",
      "The search continues",
      "The array is sorted",
      "The index is reset"
    ],
    "correct": 0,
    "explanation": "Once the target is found, the algorithm returns its position and terminates."
  },
  {
    "question": "The implementation of linear search returns -1 when:",
    "options": [
      "The array is null",
      "The target is the first element",
      "The target is not found",
      "The target is the last element"
    ],
    "correct": 2,
    "explanation": "This is a common convention used to indicate that the target was not present in the array."
  },
  {
    "question": "Which of the following statements is true about binary search?",
    "options": [
      "It can be performed on an unsorted array.",
      "It requires less memory than linear search.",
      "It is faster than linear search on average.",
      "It involves checking each element one by one."
    ],
    "correct": 2,
    "explanation": "Binary search is faster than linear search on average, especially for large datasets."
  },
  {
    "question": "An example of a situation where linear search would be preferable is:",
    "options": [
      "Searching in large sorted arrays",
      "Searching small unsorted datasets",
      "When time complexity is crucial",
      "When data is in a binary search tree"
    ],
    "correct": 1,
    "explanation": "For small datasets, the overhead of sorting for binary search may outweigh its benefits."
  },
  {
    "question": "Linear search is efficient for large datasets.",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "Linear search has O(n) time complexity, which is inefficient for large arrays."
  },
  {
    "question": "For binary search, the array must be sorted.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, binary search depends on the order of the elements to eliminate parts of the array."
  },
  {
    "question": "The time complexity of binary search is O(n).",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "No, binary search runs in O(log n) time."
  },
  {
    "question": "Both linear search and binary search can return the index of the found element.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, both algorithms can be implemented to return the index of the target if found."
  },
  {
    "question": "Binary search can be implemented using recursion.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, binary search is often implemented recursively due to its divide-and-conquer nature."
  },
  {
    "question": "Linear search is useful when the dataset is very large and sorted.",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "No, binary search is more suitable for large sorted datasets."
  },
  {
    "question": "The element being searched for can be present more than once in an array, and linear search will find one of its occurrences.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, linear search finds the first occurrence unless modified to find all occurrences."
  },
  {
    "question": "Binary search can be implemented without knowing the length of the collection.",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "No, binary search requires knowledge of the start and end indices."
  },
  {
    "question": "Linear search can be optimized to give better performance for specific cases.",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "While basic linear search cannot be significantly optimized, some variations exist for certain use cases."
  },
  {
    "question": "The mid-point calculation in a binary search can cause integer overflow in some programming languages.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, particularly in languages like Java or C++ where integer overflow can occur with large arrays."
  },
  {
    "question": "If the target element is less than the middle element in binary search, the right half of the collection is ignored.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, this is how binary search narrows down the search space."
  },
  {
    "question": "The main loop of a linear search terminates when the target element is found.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, the loop breaks as soon as the element is located."
  },
  {
    "question": "In a binary search, if the target is less than the last element, it is guaranteed to be in the left sub-array.",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "No, only if the array is sorted and the comparison is made with the middle element."
  },
  {
    "question": "Both searching algorithms can be implemented in the same programming environment.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, both can be implemented in any language that supports basic loops and conditionals."
  },
  {
    "question": "Binary search is always the preferred method for searching, regardless of the dataset's state.",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "No, linear search is preferred for small or unsorted datasets."
  },
  {
    "question": "A linear search can correctly identify if there are duplicates in an array.",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "No, while linear search can detect duplicates during traversal, it doesn't inherently check for them."
  },
  {
    "question": "The efficiency of a search algorithm is determined solely by its time complexity.",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "No, other factors such as space complexity and real-world performance also matter."
  },
  {
    "question": "Linear search requires no additional data structure.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, it works directly on the input array without needing extra storage."
  },
  {
    "question": "Binary search can find the target value faster than linear search for nearly all cases.",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "No, for very small or unsorted datasets, linear search might be faster."
  },
  {
    "question": "The linear search algorithm is usually easier to implement than the binary search.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, linear search uses a simple loop without the need for dividing ranges."
  },
  {
    "question": "What type of algorithm is Merge Sort?",
    "options": [
      "Greedy",
      "Divide and Conquer",
      "Dynamic Programming",
      "Backtracking"
    ],
    "correct": 1,
    "explanation": "Merge Sort follows a divide-and-conquer approach by splitting the array, sorting subarrays, and merging them back together."
  },
  {
    "question": "How many elements are in each subarray when Merge Sort has completed its recursive division?",
    "options": ["One", "Two", "Three", "Four"],
    "correct": 0,
    "explanation": "Merge Sort divides the array recursively until each subarray contains only one element."
  },
  {
    "question": "What is the time complexity of Merge Sort?",
    "options": ["O(n)", "O(n^2)", "O(log n)", "O(n log n)"],
    "correct": 3,
    "explanation": "Merge Sort runs in O(n log n) time for all cases due to its divide-and-conquer structure."
  },
  {
    "question": "During the merging phase, what does the algorithm primarily accomplish?",
    "options": [
      "Divide the array further",
      "Sort and merge the subarrays",
      "Randomize the array",
      "None of the above"
    ],
    "correct": 1,
    "explanation": "The merge step combines two sorted subarrays into a single sorted array."
  },
  {
    "question": "What is required for the merging step in Merge Sort?",
    "options": [
      "Two temporary arrays",
      "One temporary array",
      "A sorting library",
      "No extra space"
    ],
    "correct": 0,
    "explanation": "Typically, two temporary arrays are used to hold the left and right halves during the merge process."
  },
  {
    "question": "What is the space complexity of Merge Sort due to temporary arrays?",
    "options": ["O(1)", "O(n)", "O(log n)", "O(n log n)"],
    "correct": 1,
    "explanation": "Merge Sort requires additional memory proportional to the size of the input array."
  },
  {
    "question": "Merge Sort is well-suited for:",
    "options": [
      "Small datasets",
      "Large datasets",
      "When memory is limited",
      "Only for sorted data"
    ],
    "correct": 1,
    "explanation": "Its consistent O(n log n) performance makes it ideal for large datasets."
  },
  {
    "question": "In Merge Sort, the base case for recursion occurs when:",
    "options": [
      "The array has multiple elements",
      "The array is sorted",
      "The subarray has only one element",
      "The array is empty"
    ],
    "correct": 2,
    "explanation": "Recursion stops when the subarray contains only one element, which is inherently sorted."
  },
  {
    "question": "Merge Sort is stable. What does this mean?",
    "options": [
      "It is faster than other algorithms",
      "It preserves the relative order of equal elements",
      "It requires less memory",
      "It is not affected by input order"
    ],
    "correct": 1,
    "explanation": "Stability ensures that equal elements retain their original order after sorting."
  },
  {
    "question": "Which of the following steps is NOT part of the Merge Sort algorithm?",
    "options": [
      "Splitting the array",
      "Merging subarrays",
      "Randomizing elements",
      "Recursion"
    ],
    "correct": 2,
    "explanation": "Merge Sort does not involve randomization; it's a deterministic algorithm."
  },
  {
    "question": "Merge Sort can be implemented using both recursion and iteration.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, although the recursive version is more common, an iterative version also exists."
  },
  {
    "question": "The merge step of Merge Sort takes O(1) time.",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "No, the merge step takes O(n) time as it processes all elements in the subarrays."
  },
  {
    "question": "Merge Sort can be used for linked lists more efficiently than for arrays.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, because linked lists allow efficient insertion and merging without needing extra space."
  },
  {
    "question": "The space complexity of Merge Sort is O(log n).",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "No, the space complexity is O(n) due to the need for temporary arrays."
  },
  {
    "question": "After the merge operation, the entire array is sorted correctly.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, the merge process ensures that all subarrays are combined into a fully sorted array."
  },
  {
    "question": "Merge Sort requires more space than Quick Sort.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, Merge Sort uses O(n) space while Quick Sort is typically in-place with O(log n) stack space."
  },
  {
    "question": "Merge Sort is faster than Bubble Sort for all input sizes.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, Bubble Sort has O(n²) time complexity, which is worse than Merge Sort's O(n log n)."
  },
  {
    "question": "Merge Sort is not suitable for sorting a small number of items.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, for small datasets, simpler algorithms like Insertion Sort are often more efficient."
  },
  {
    "question": "The division step of Merge Sort cuts the array into three sections.",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "No, Merge Sort divides the array into two halves at each step."
  },
  {
    "question": "Merge Sort can be adapted for external sorting where data is too large to fit into memory.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, Merge Sort is commonly used in external sorting applications due to its sequential access pattern."
  },

  {
    "question": "In which scenario would Merge Sort generally perform worse?",
    "options": [
      "When the input is small",
      "When the input is large",
      "When the array is already sorted",
      "When memory is not an issue"
    ],
    "correct": 0,
    "explanation": "For small datasets, the overhead of recursion and memory usage makes it slower compared to simple algorithms."
  },
  {
    "question": "What is the main disadvantage of Merge Sort?",
    "options": [
      "It is not stable",
      "It requires extra storage space",
      "It has a high time complexity",
      "It is difficult to implement"
    ],
    "correct": 1,
    "explanation": "Merge Sort uses additional memory, making it less efficient in terms of space."
  },
  {
    "question": "In Merge Sort, how many levels does the recursion generate for an array of size n?",
    "options": ["n", "log₂(n)", "n^2", "n log n"],
    "correct": 1,
    "explanation": "Each level splits the array in half, resulting in log₂(n) levels of recursion."
  },
  {
    "question": "Merge Sort can sort elements in descending order by simply reversing the comparison during the merge step.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, by changing the comparison logic from '<' to '>', you can sort in descending order."
  },
  {
    "question": "Merge Sort is an in-place sorting algorithm.",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "No, Merge Sort requires additional memory for merging, so it is not in-place."
  },
  {
    "question": "The main component of Merge Sort is the divide step, which splits the array.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, the divide step is essential for breaking the problem into smaller subproblems."
  },
  {
    "question": "All sorting algorithms are stable.",
    "options": ["True", "False"],
    "correct": 1,
    "explanation": "No, some algorithms like Quick Sort are unstable unless specifically modified."
  },
  {
    "question": "An array that is already sorted will still require O(n log n) operations for Merge Sort.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, Merge Sort always performs O(n log n) operations regardless of the initial order."
  },
  {
    "question": "The merge function in Merge Sort can be optimized to use less memory.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, there are in-place variants and optimizations to reduce memory usage."
  },
  {
    "question": "The overall performance of Merge Sort can be affected by the size of the input data.",
    "options": ["True", "False"],
    "correct": 0,
    "explanation": "Yes, although the time complexity remains O(n log n), actual runtime increases with larger inputs."
  }
]
